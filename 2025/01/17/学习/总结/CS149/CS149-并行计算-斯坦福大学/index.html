<!DOCTYPE html><html lang="en" theme-mode="dark"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>CS149-并行计算-斯坦福大学-学习笔记 | wwnao</title><link rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="preload" as="font" crossorigin="anonymous" href="/font/Bender.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/BenderLight.ttf"><link rel="preload" as="font" crossorigin="anonymous" href="/font/JetBrainsMono-Regular.woff2"><link rel="stylesheet" href="/css/arknights.css"><style>@font-face {
  font-family: Bender;
  src: local('Bender'), url("/font/Bender.ttf"), url("/font/Bender.otf");
}
@font-face {
  font-family: BenderLight;
  src: local('BenderLight'), url("/font/BenderLight.ttf");
}
@font-face {
  font-family: 'JetBrains Mono';
  src: local('JetBrains Mono'), url('/font/JetBrainsMono-Regular.woff2') format('woff2');
}
</style><script>var config = {"root":"/","search":{"preload":false,"activeHolder":"Enter here","blurHolder":"Search","noResult":"Data \"$0\" not found"},"code":{"codeInfo":"$0 - $1 lines","copy":"copy"}}</script><link type="text/css" rel="stylesheet" href="/lib/encrypt/hbe.style.css"><script src="//unpkg.com/mermaid@10.5.0/dist/mermaid.min.js"></script><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lightgallery.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-zoom.css"><link type="text/css" rel="stylesheet" href="//unpkg.com/lightgallery@2.7.1/css/lg-thumbnail.css"><link type="text/css" rel="stylesheet" href="/lib/fontawesome/css/all.min.css"><script>if (window.localStorage.getItem('theme-mode') === 'light')
 document.documentElement.setAttribute('theme-mode', 'light')
if (window.localStorage.getItem('theme-mode') === 'dark')
 document.documentElement.setAttribute('theme-mode', 'dark')</script><style>@font-face {
 font-family: BenderLight;
 src: local('Bender'), url("/font/BenderLight.woff2") format('woff2');
}
@font-face {
 font-family: 'JetBrains Mono';
 src: local('JetBrains Mono'), url('/font/JetBrainsMono-Regular.woff2') format('woff2');
}</style><style>:root {
 --dark-background: url('https://ak.hypergryph.com/assets/index/images/ak/pc/bk.jpg');
 --light-background: url('/img/bk.jpg');
 --theme-encrypt-confirm: 'confirm'
}</style><script defer src="/js/arknights.js"></script><script defer src="/js/search.js"></script><script defer type="module">import mermaid from '//unpkg.com/mermaid@10.5.0/dist/mermaid.esm.mjs';
window.mermaid = mermaid;
code.paintMermaid();
</script><script async src="//unpkg.com/lightgallery@2.7.1/lightgallery.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/zoom/lg-zoom.min.js"></script><script async src="//unpkg.com/lightgallery@2.7.1/plugins/thumbnail/lg-thumbnail.min.js"></script><script async src="/lib/encrypt/hbe.js"></script><script async src="/js/pjax.js"></script><script class="pjax-js">reset= () => {document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js','data-pjax','.busuanzi'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);reset()})</script><script class="pjax-js">reset= () => {document.querySelector('.lg-container')?.remove()
lightGallery(document.getElementById('post-bg'), {
  plugins: [lgZoom,lgThumbnail],
  selector: '.item-img'})}</script><script>window.addEventListener("load",() => {pjax = new Pjax({
 cacheBust: false,
 selectors: ['title','article','#aside-block','.pjax-js'],
 switches: {'article': Pjax.switches.sideBySide},
 switchesOptions: {
   'article': {
     classNames: {
       remove: "pjax-out",
       add: "pjax-in"
     }
   }
 }
});
document.addEventListener("pjax:complete", reset);reset()})</script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="loading" style="opacity: 0;"><div class="loadingBar left"></div><div class="loadingBar right"></div></div><main><header class="closed"><div class="navBtn"><i class="navBtnIcon"><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span><span class="navBtnIconBar"></span></i></div><nav><div class="navItem" id="search-header"><span class="navItemTitle"><input autocomplete="off" autocorrect="off" autocapitalize="none" placeholder="Search" spellcheck="false" maxlength="50" type="text" id="search-input"></span></div><div class="navItem" id="search-holder"></div><div class="search-popup" tabindex="0"><div id="search-result"></div></div><ol class="navContent"><li class="navItem"><a class="navBlock" href="/"><span class="navItemTitle">Home</span></a></li><li class="navItem" matchdata="categories,tags"><a class="navBlock" href="/archives/"><span class="navItemTitle">Archives</span></a></li></ol></nav></header><article><div id="post-bg"><div id="post-title"><h1>CS149-并行计算-斯坦福大学-学习笔记</h1></div><hr><div id="post-content"><h1 id="CS149-并行计算-斯坦福大学-学习笔记"><a href="#CS149-并行计算-斯坦福大学-学习笔记" class="headerlink" title="CS149-并行计算-斯坦福大学-学习笔记"></a>CS149-并行计算-斯坦福大学-学习笔记</h1><ul>
<li>讲师: Kayvon Fatahalian, Kunle Olukotun</li>
<li>课程录播（中英字幕，部分有误，fall 23）：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1du17YfE5G">https://www.bilibili.com/video/BV1du17YfE5G</a></li>
<li>课程官网（fall 24）：<a target="_blank" rel="noopener" href="https://gfxcourses.stanford.edu/cs149/fall24">https://gfxcourses.stanford.edu/cs149/fall24</a></li>
<li>编程作业（fall24）：<ol>
<li>在四核 CPU 上分析并行程序性能</li>
<li>在多核 CPU 上调度任务图</li>
<li>用 CUDA 实现一个简单的渲染器</li>
<li>在 DNN 加速硬件上优化深度神经网络（DNN）性能。（实现和优化 AWS Trainium 架构的内核）</li>
<li>使用 OpenMP 处理大规模图数据</li>
<li>（fall23 原第三题）chat149: 小语言模型，用 C++ 实现基于 DNN 的 transformer 的注意力层（flash-attention）</li>
</ol>
</li>
</ul>
<blockquote>
<p><strong>（fall24）课程导言</strong>：<br>从智能手机到多核 CPU 和 GPU，再到世界上最大的超级计算机和网站，并行处理在现代计算中无处不在。本课程的目标是深入了解设计现代并行计算系统所涉及的基本原理和工程权衡，并教授有效利用这些机器所需的并行编程技术。因为编写好的并行程序需要了解关键的机器性能特征，所以本课程将涵盖并行硬件和软件设计。</p>
</blockquote>
<h1 id="其一：Why-Parallelism-Why-Efficiency"><a href="#其一：Why-Parallelism-Why-Efficiency" class="headerlink" title="其一：Why Parallelism? Why Efficiency?"></a>其一：Why Parallelism? Why Efficiency?</h1><blockquote>
<p>第一章：为什么要并行？为什么要高效率？</p>
</blockquote>
<blockquote>
<p>Fast !&#x3D; Efficient</p>
<p>速度快，不等于效率高</p>
</blockquote>
<blockquote>
<p>如果老板给了你 100 倍的算力设备，<br>你却仅仅将程序加快了 2 倍，<br>我想你就该被开除了。</p>
<p>“是的，让他去重修 CS149。”</p>
</blockquote>
<h2 id="demo1：第一个并行程序"><a href="#demo1：第一个并行程序" class="headerlink" title="demo1：第一个并行程序"></a>demo1：第一个并行程序</h2><blockquote>
<p>案例：</p>
<ul>
<li>1 人可以在 45 秒内算出 16 个数的总和。（demo1：第一个并行程序）</li>
<li>但 2 人并不能在 23 秒内算出 16 个数字的总和，而是 40 秒。</li>
<li>4 人计算 16 个数字之和的时间，优化到了 19 秒，而不是 12 秒。（demo2：扩展到 4 个“处理器”）</li>
<li>100 多人不能在 2 分钟内数清楚人数总和。（demo3：大批量并行执行）</li>
</ul>
</blockquote>
<p>这个案例告诉我们：<br>并行计算，关键不在于如何并行，如何计算（虽然这也很重要），关键在于数据传输和协同效率。</p>
<p>因此，我们更多的是在学习：如何传输数据，排列数据，而不是写代码或布局硬件。</p>
<h2 id="什么是计算机程序？-What-is-a-computer-program"><a href="#什么是计算机程序？-What-is-a-computer-program" class="headerlink" title="什么是计算机程序？ What is a computer program ?"></a>什么是计算机程序？ What is a computer program ?</h2><blockquote>
<p>A program is a list of processor instructions!</p>
</blockquote>
<p>“程序（program）”不同于“代码（code）”。</p>
<p>程序，与食谱一样，应当是可执行的一系列命题（操作流程）。</p>
<p>计算机程序，则是“指令流”，或者叫“指令序列”。<br>必须是计算机认识的一系列 01 串。</p>
<h2 id="处理器做了什么？-What-does-a-processor-do"><a href="#处理器做了什么？-What-does-a-processor-do" class="headerlink" title="处理器做了什么？ What does a processor do ?"></a>处理器做了什么？ What does a processor do ?</h2><p>一个简化的处理器有 3 个模块：</p>
<ul>
<li>Fetch &#x2F; Decode： 取指令、解析指令</li>
<li>ALU：算数运算单元</li>
<li>Execution Context：执行上下文</li>
</ul>
<h2 id="案例：a-x-x-y-y-z-z"><a href="#案例：a-x-x-y-y-z-z" class="headerlink" title="案例：a = x * x + y * y + z * z"></a>案例：<code>a = x * x + y * y + z * z</code></h2><p>这个简单的多项式运算会编译出 5 条指令<br>（假设使用 r1，r2，r3 寄存器，<br>假设不使用任何编译优化<br><a href="#%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96chatgpt">编译优化（ChatGPT）</a><br>）：</p>
<ol>
<li>mul r1, r1, r1</li>
<li>mul r2, r2, r2</li>
<li>mul r3, r3, r3</li>
<li>add r1, r1, r2 ; r1 &#x3D; r1 + r2</li>
<li>add r1, r1, r3</li>
</ol>
<p>我们发现，指令 4 依赖于指令 1、2；指令 5 依赖于指令 3、4。<br>所以，等待是必须的，即使使用 5 个 cpu，效率也不会超过 1 条 mul 指令时间加上 2 条 add 指令时间。</p>
<p>（这里还有寄存器最少使用原则，或最多使用原则，不做讨论）</p>
<p>如何进一步提高性能？</p>
<ul>
<li>数学家：改进数学公式，减少乘法次数（耗时长的操作），增加加法次数（耗时短的操作），重新编写代码。</li>
<li>硬件工程师：指令重排，指令随机化，指令流水线，分支预测，多级缓存，自动并行化，自动向量化加速</li>
<li>软件工程师：编写高维度的，可并行化的程序。任务并行化，数据结构并行化，计算并行化，数据传输并行化，数据存储并行化。主动使用缓存（预存器）。</li>
</ul>
<blockquote>
<p>小结</p>
<ul>
<li>软件：物尽其用（压榨硬件的一切性能）</li>
<li>硬件：用尽其物（挑选更好的硬件去适配软件）</li>
</ul>
</blockquote>
<h2 id="编译优化（ChatGPT）"><a href="#编译优化（ChatGPT）" class="headerlink" title="编译优化（ChatGPT）"></a>编译优化（ChatGPT）</h2><p>现代编译器通常会结合多种优化策略，来提高程序的执行效率。它们会根据不同的场景、硬件架构和程序的特征，选择不同的原则来优化寄存器的使用。以下是一些现代编译器普遍采用的优化原则和策略：</p>
<h3 id="1-寄存器最多使用原则（Maximizing-Register-Usage）"><a href="#1-寄存器最多使用原则（Maximizing-Register-Usage）" class="headerlink" title="1. 寄存器最多使用原则（Maximizing Register Usage）"></a>1. <strong>寄存器最多使用原则（Maximizing Register Usage）</strong></h3><p>现代编译器在许多情况下倾向于使用尽可能多的寄存器，这样可以减少对内存的访问，因为寄存器的访问速度远快于内存。这个原则通常用于以下情况：</p>
<ul>
<li><strong>频繁访问的变量</strong>：如果某个变量在计算中被频繁使用，编译器会尽可能地将其保留在寄存器中，避免频繁的内存读写操作。</li>
<li><strong>局部性原理</strong>：寄存器的使用能很好地利用数据的局部性。例如，如果某个数据在一段时间内频繁访问，它可以存储在寄存器中，而不需要每次从内存中读取。</li>
</ul>
<p><strong>举例</strong>：对于一个简单的多项式计算：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">a = x * x + y * y + z * z;<br></code></pre></td></tr></table></figure>

<p>编译器可能会为每个中间结果（如 <code>x * x</code>、<code>y * y</code>、<code>z * z</code>）分配一个寄存器，并将结果存储在寄存器中，避免额外的内存操作。</p>
<h3 id="2-寄存器分配和寄存器重命名"><a href="#2-寄存器分配和寄存器重命名" class="headerlink" title="2. 寄存器分配和寄存器重命名"></a>2. <strong>寄存器分配和寄存器重命名</strong></h3><ul>
<li><strong>寄存器分配</strong>：编译器通过分析程序的数据流和生命周期来确定哪些变量应该保留在寄存器中。寄存器的分配不仅考虑变量的使用频率，还要避免寄存器冲突，尽可能地减少寄存器的交换和保存操作。</li>
<li><strong>寄存器重命名</strong>：现代编译器会使用寄存器重命名技术来避免因寄存器依赖（如数据依赖）而产生的性能瓶颈。通过给同一个物理寄存器分配多个逻辑寄存器，编译器可以让多个指令并行执行，避免等待依赖关系完成。</li>
</ul>
<h3 id="3-局部变量优化"><a href="#3-局部变量优化" class="headerlink" title="3. 局部变量优化"></a>3. <strong>局部变量优化</strong></h3><p>现代编译器通常会通过 <strong>局部性分析</strong> 来优化寄存器的使用。局部变量是那些只在函数内部使用的变量，编译器会尽量将它们分配到寄存器中，而不是存储在栈上或堆上。特别是对于小型的、生命周期较短的局部变量，寄存器使用能显著提高性能。</p>
<p><strong>举例</strong>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> sum = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++) &#123;<br>    sum += arr[i];<br>&#125;<br></code></pre></td></tr></table></figure>

<p>编译器可能会将 <code>sum</code> 和 <code>i</code> 变量都存储在寄存器中，以减少对内存的访问。</p>
<h3 id="4-内联扩展（Inlining）"><a href="#4-内联扩展（Inlining）" class="headerlink" title="4. 内联扩展（Inlining）"></a>4. <strong>内联扩展（Inlining）</strong></h3><p>编译器会尝试对一些小的、频繁调用的函数进行内联扩展（inline），将函数调用替换成函数的实现体。这可以消除函数调用的开销，并减少对寄存器和内存的使用，特别是在递归或频繁调用的情况下。</p>
<h3 id="5-循环优化（Loop-Optimization）"><a href="#5-循环优化（Loop-Optimization）" class="headerlink" title="5. 循环优化（Loop Optimization）"></a>5. <strong>循环优化（Loop Optimization）</strong></h3><p>编译器对循环结构进行优化，以提高寄存器的利用率和减少内存访问。例如，编译器可能会将循环展开、循环重排或循环分割，以便使计算更密集，从而减少内存的读取次数。</p>
<p><strong>举例</strong>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++) &#123;<br>    a[i] = b[i] + c[i];<br>&#125;<br></code></pre></td></tr></table></figure>

<p>编译器可能将其优化为多个操作并行执行，或者将内存访问合并，以更高效地利用寄存器。</p>
<h3 id="6-寄存器压力和溢出（Register-Pressure-and-Spill）"><a href="#6-寄存器压力和溢出（Register-Pressure-and-Spill）" class="headerlink" title="6. 寄存器压力和溢出（Register Pressure and Spill）"></a>6. <strong>寄存器压力和溢出（Register Pressure and Spill）</strong></h3><p>现代编译器会根据寄存器的使用情况动态调整优化策略。如果寄存器使用过多，导致“寄存器压力”过大，编译器就可能将某些值溢出（spill）到栈上，特别是在寄存器资源紧张的情况下。溢出操作会影响性能，因为它需要额外的内存读写操作。</p>
<h3 id="7-自动向量化"><a href="#7-自动向量化" class="headerlink" title="7. 自动向量化"></a>7. <strong>自动向量化</strong></h3><p>现代编译器（如 GCC、Clang、Intel 的 ICC 编译器等）支持自动向量化。通过向量化，编译器可以将标量操作转化为 SIMD（单指令多数据流）操作，这样能够将多个计算任务并行地放到同一个寄存器组中，从而大幅提高计算效率。</p>
<p><strong>举例</strong>：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; N; i++) &#123;<br>    a[i] = b[i] + c[i];<br>&#125;<br></code></pre></td></tr></table></figure>

<p>如果编译器支持向量化，它可能会将这段代码转换成可以同时加法多个元素的 SIMD 指令，使得多个数组元素能够同时在寄存器中处理，从而提高性能。</p>
<h3 id="8-多级缓存和数据局部性"><a href="#8-多级缓存和数据局部性" class="headerlink" title="8. 多级缓存和数据局部性"></a>8. <strong>多级缓存和数据局部性</strong></h3><p>现代编译器也会考虑缓存的优化，尽量减少从内存中读取的数据量，利用 CPU 的多级缓存（L1、L2、L3 缓存）。通过优化程序的数据访问模式和寄存器分配，编译器能够使数据尽可能保持在较快的缓存中，而不需要频繁访问较慢的主内存。</p>
<h3 id="9-并行计算和多核优化"><a href="#9-并行计算和多核优化" class="headerlink" title="9. 并行计算和多核优化"></a>9. <strong>并行计算和多核优化</strong></h3><p>在多核处理器上运行时，编译器可能会自动将程序分割成多个并行线程，使用多核的并行性来加速计算。寄存器的分配和使用会考虑到多线程并发执行的情况，确保每个线程能够高效地利用本地寄存器。</p>
<h3 id="10-指令级并行性（ILP）优化"><a href="#10-指令级并行性（ILP）优化" class="headerlink" title="10. 指令级并行性（ILP）优化"></a>10. <strong>指令级并行性（ILP）优化</strong></h3><p>编译器会使用一些高级技术（如指令重排、延迟槽填充、分支预测等）来优化指令级并行性。这些优化措施通过重新排列指令，减少指令间的依赖关系，从而更好地利用寄存器和其他硬件资源，提高程序的执行效率。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>现代编译器会综合考虑性能、内存带宽、寄存器数量、计算依赖关系等多种因素，使用寄存器最多使用原则来最大化寄存器的利用率，但也会根据具体的硬件架构和程序的特性做适当的调整。最终目标是减少内存访问、提高并行性，并通过智能的寄存器分配和优化技术提升整体性能。</p>
<h1 id="其二：A-Modern-Muti-Core-Processor"><a href="#其二：A-Modern-Muti-Core-Processor" class="headerlink" title="其二：A Modern Muti-Core Processor"></a>其二：A Modern Muti-Core Processor</h1><blockquote>
<p>第二章：现代多核处理器</p>
</blockquote>
<h2 id="案例：计算-y-i-sin-x-i"><a href="#案例：计算-y-i-sin-x-i" class="headerlink" title="案例：计算 y[i]=sin(x[i])"></a>案例：计算 <code>y[i]=sin(x[i])</code></h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">void</span> <span class="hljs-title function_">sinx</span><span class="hljs-params">(<span class="hljs-type">int</span> N, <span class="hljs-type">int</span> terms, <span class="hljs-type">float</span>* x, <span class="hljs-type">float</span>* y)</span><br>&#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>; i&lt;N; i++)<br>    &#123;<br>        <span class="hljs-type">float</span> value = x[i];<br>        <span class="hljs-type">float</span> numer = x[i] * x[i] * x[i];<br>        <span class="hljs-type">int</span> denom = <span class="hljs-number">6</span>; <span class="hljs-comment">// 3!</span><br>        <span class="hljs-type">int</span> sign = <span class="hljs-number">-1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j=<span class="hljs-number">1</span>; j&lt;=terms; j++)<br>        &#123;<br>            value += sign * numer / denom;<br>            numer *= x[i] * x[i];<br>            denom *= (<span class="hljs-number">2</span>*j + <span class="hljs-number">2</span>) * (<span class="hljs-number">2</span>*j + <span class="hljs-number">3</span>);<br>            sign *= <span class="hljs-number">-1</span>;<br>        &#125;<br>      y[i] = value;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>这段程序计算 <code>y[i] = sin(x[i])</code>，<br>N 为数组长度，<br>terms 则是精度（泰勒展开项个数）。</p>
<p>暂且不谈这段程序在优化方面，<br>利用了之前的计算结果来计算 x 的幂次与 j 的阶乘，<br>这种做法的精妙之处，<br>以及使用 for 循环和局部变量，而不是函数，<br>带来的更高程度的局部性，<br>也不考虑运算溢出问题。<br>我们只关心，如何并行化计算。</p>
<h4 id="高维度并行化（调用方并行）"><a href="#高维度并行化（调用方并行）" class="headerlink" title="高维度并行化（调用方并行）"></a>高维度并行化（调用方并行）</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>    <span class="hljs-type">int</span> N;<br>    <span class="hljs-type">int</span> terms;<br>    <span class="hljs-type">float</span>* x;<br>    <span class="hljs-type">float</span>* y;<br>&#125; my_args;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">my_thread_func</span><span class="hljs-params">(my_args* args)</span><br>&#123;<br>  sinx(args-&gt;N, args-&gt;terms, args-&gt;x, args-&gt;y); <span class="hljs-comment">// do work</span><br>&#125;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">parallel_sinx</span><span class="hljs-params">(<span class="hljs-type">int</span> N, <span class="hljs-type">int</span> terms, <span class="hljs-type">float</span>* x, <span class="hljs-type">float</span>* y)</span><br>&#123;<br>  <span class="hljs-built_in">std</span>::thread my_thread;<br>  my_args args;<br><br>  args.N = N/<span class="hljs-number">2</span>;<br>  args.terms  = terms;<br>  args.x = x;<br>  args.y = y;<br><br>  my_thread = <span class="hljs-built_in">std</span>::thread(my_thread_func, &amp;args); <span class="hljs-comment">// launch thread</span><br>  sinx(N - args.N, terms, x + args.N, y + args.N); <span class="hljs-comment">// do work on main thread</span><br>  my_thread.join(); <span class="hljs-comment">// wait for thread to complete</span><br>&#125;<br></code></pre></td></tr></table></figure>

<p>其中 <code>sinx()</code> 的定义同上。</p>
<p>老师给出的代码，<br>实现了 main 线程和子线程并行计算一串 <code>y[i]=sin(x[i])</code>。<br>主线程计算后半段，子线程计算前半段。<br>用指针运算，巧妙地在调用方进行了并行化<br>（即老师所说“更高维度的并行化”）。</p>
<p>但是，并不是所有程序都能做到这样良好的并行化。</p>
<h4 id="向量编程（底层并行）"><a href="#向量编程（底层并行）" class="headerlink" title="向量编程（底层并行）"></a>向量编程（底层并行）</h4><p>AVX intrinsics<br class='item-img' data-src='/imgs/cs149/cs149-slide_034.jpg'><img src="/imgs/cs149/cs149-slide_034.jpg" alt="向量编程 AVX intrinsics"></p>
<h3 id="条件分支"><a href="#条件分支" class="headerlink" title="条件分支"></a>条件分支</h3><p class='item-img' data-src='/imgs/cs149/cs149-slide_039.jpg'><img src="/imgs/cs149/cs149-slide_039.jpg" alt="cs149-slide_039.jpg"></p>
<p>在现代向量运算器上，<br>比如 8 个单元的 ALU，<br>并不是每个单元都能有效利用<br>（每个单元都有自己的数据要处理，<br>有自己的条件判断分支）。<br>程序不可避免需要 if else 语句，<br>这就导致有的时候我们并不能充分发挥并行计算的全部性能<br>（也就是没做到“物尽其用”的硬件性能压榨）。</p>
<p>老师问：<br>有没有一种 if 语句，<br>能让并行化的性能反而降低为 1&#x2F;8？</p>
<p>答案是：<br>if 里进行模 8 判断，<br>在 1&#x2F;8 的情况下进入代码块 1，<br>在 7&#x2F;8 的情况下进入代码块 2，<br>但代码块 1 所做的事情是代码块 2 的很多很多倍<br>（极端情况是代码块 1 执行所有计算，<br>代码块 2 不执行计算），<br>这样总体性能就约等于 1&#x2F;8。</p>
<p>为了避免在大多数情况下进入低性能运算分支，<br>我们应当仔细考察运算过程，<br>写出“高并行化”的“高性能”代码。</p>
<h2 id="现代多核处理器"><a href="#现代多核处理器" class="headerlink" title="现代多核处理器"></a>现代多核处理器</h2><h3 id="3-种不同形式的并行执行"><a href="#3-种不同形式的并行执行" class="headerlink" title="3 种不同形式的并行执行"></a>3 种不同形式的并行执行</h3><ul>
<li><strong>超标量（Superscalar）</strong>：利用指令流中的 ILP。并行处理同一指令流中的不同指令（只用一个核心（core））。<ul>
<li>在执行过程中，硬件自动发现并行性。（发现一小段程序中有几条指令可以并行执行）</li>
</ul>
</li>
<li><strong>单指令流多数据流（SIMD）（Single Instruction Multiple Data）</strong>：一条指令控制多个 ALU（只用一个核心）。<ul>
<li>高效处理数据并行工作负载：摊销对多个 ALU 的控制成本。</li>
<li>由编译器（显式 SIMD）或在运行时由硬件（隐式 SIMD）进行向量化</li>
</ul>
</li>
<li><strong>多核（Multi-core）</strong>：使用多个处理核心<ul>
<li><strong>提供线程级并行</strong>：在每个核上同时执行完全不同的指令流</li>
<li>软件创建线程以向硬件公开并行性（例如，通过线程 API）</li>
</ul>
</li>
</ul>
<h3 id="现代多核处理器-1"><a href="#现代多核处理器-1" class="headerlink" title="现代多核处理器"></a>现代多核处理器</h3><p>回顾一下第一章的简单处理器架构：</p>
<ul>
<li>Fetch &#x2F; Decode： 取指令、解析指令</li>
<li>ALU（Execution）：算数运算单元（执行器）</li>
<li>Execution Context：执行上下文</li>
</ul>
<p>简单扩展一下，利用前面提到的三种并行化策略，<br>我们就可以得到：</p>
<ul>
<li><strong>单核、超标量处理器</strong>：<ul>
<li>2 个取指器&#x2F;解析器</li>
<li>每个取指器对应 1 个执行器</li>
<li>多个执行器共用一个上下文</li>
</ul>
</li>
<li><strong>多核处理器</strong>：<ul>
<li>就是多个核心复制粘贴（不考虑数据、缓存交流等）</li>
</ul>
</li>
<li><strong>SIMD 四核处理器（八位宽）</strong>：<ul>
<li>4 个核心</li>
<li>每个核心 1 个取指器</li>
<li>每个核心 8 个 ALU（8-wide SIMD）</li>
<li>每个核心 1 个上下文</li>
</ul>
</li>
<li><blockquote>
<p class='item-img' data-src='/imgs/cs149/cs149-slide_046.jpg'><img src="/imgs/cs149/cs149-slide_046.jpg" alt="示例简单多核处理器"></p>
</blockquote>
</li>
<li><strong>四核 Intel i7-7700k CPU</strong>:<ul>
<li>4 核心</li>
<li>每个核心 1 个上下文</li>
<li>每个核心有 3 个 8 位宽 SIMD ALUs（AVX2 instructions）（每个核心 3 个取指器，每个取指器 8 个 ALU）</li>
<li>浮点运算性能：4（核） * 8（位宽）* 3（个）* 4.2Ghz &#x3D; 400GFLOPs</li>
</ul>
</li>
<li><blockquote>
<p class='item-img' data-src='/imgs/cs149/cs149-slide_047.jpg'><img src="/imgs/cs149/cs149-slide_047.jpg" alt="Intel i7-7700k CPU"></p>
</blockquote>
</li>
<li><strong>NVIDIA V100 GPU</strong><ul>
<li>80 个“SM（Streaming Multiprocessor）” 核心</li>
<li>128 个 SIMD ALUs 每”SM”(@1.6 GHz)&#x3D;16 TFLOPs (~250 Watts)</li>
</ul>
</li>
</ul>
<h2 id="第二部分：访问内存（Part2：accessing-memory）"><a href="#第二部分：访问内存（Part2：accessing-memory）" class="headerlink" title="第二部分：访问内存（Part2：accessing memory）"></a>第二部分：访问内存（Part2：accessing memory）</h2><h4 id="回想：非常长的数据访问延迟"><a href="#回想：非常长的数据访问延迟" class="headerlink" title="回想：非常长的数据访问延迟"></a>回想：非常长的数据访问延迟</h4><p>延迟（在 4GHz 下的时钟周期数）</p>
<ul>
<li>L1 Cache：4</li>
<li>L2 Cache：12</li>
<li>L3 Cache：38</li>
<li>DRAM：~248</li>
</ul>
<h4 id="回想：缓存未命中"><a href="#回想：缓存未命中" class="headerlink" title="回想：缓存未命中"></a>回想：缓存未命中</h4><ol>
<li>冷启动未命中（Cold Miss &#x2F; Compulsory Miss）</li>
<li>容量未命中（Capacity Miss）</li>
<li>冲突未命中（Conflict Miss &#x2F; Collision Miss）</li>
<li>一致性未命中（Coherence Miss &#x2F; Invalid Miss）</li>
<li>人为失效未命中（Manual Invalidation Miss）</li>
</ol>
<h4 id="回想：数据预取"><a href="#回想：数据预取" class="headerlink" title="回想：数据预取"></a>回想：数据预取</h4><p>当访问大量连续性可预测的数据，<br>比如访问一大块数组时，<br>可以很容易进行预测，<br>并进行数据预取（data prefetch）</p>
<hr>
<p>但是，如果近期没有访问过数据，<br>也很难预测程序下一步要干嘛，怎么办？</p>
<h3 id="第-3-种方法：用多线程隐藏停顿（hide-stall）"><a href="#第-3-种方法：用多线程隐藏停顿（hide-stall）" class="headerlink" title="第 3 种方法：用多线程隐藏停顿（hide stall）"></a>第 3 种方法：用多线程隐藏停顿（hide stall）</h3><p>就像可以边烧水边炒菜一样，<br>当我们知道某种操作耗时，<br>我们就先去处理别的事情。</p>
<blockquote>
<p>等水烧开，再去关火。</p>
</blockquote>
<p>多线程，就是复制我们之前提到的处理器架构中的“上下文”。</p>
<ul>
<li>线程 1：计算，访问内存，计算。</li>
<li>线程 2：计算，访问内存，计算。</li>
<li>线程 3：计算，访问内存，计算。</li>
<li>线程 4：计算，访问内存，计算。</li>
</ul>
<p>使用一个核心，我们可以创建 4 个线程，<br>按顺序执行这些线程。<br>当线程 1 访问内存、等待数据的时候<br>（前面提到的大约 250 个时钟周期），<br>让线程 2 进行计算操作，<br>当线程 2 访问内存、等待数据的时候，<br>让线程 3 进行计算…</p>
<p>由此，我们得到了大致的多线程执行时间流：<br class='item-img' data-src='/imgs/cs149/cs149-slide_060.jpg'><img src="/imgs/cs149/cs149-slide_060.jpg" alt="用多线程隐藏停顿"><br>这个程序的 cpu 利用率为：100%</p>
<p>我们并没有减少停顿时间，<br>我们只是在停顿时间内去做别的工作。</p>
<blockquote>
<p>等待，但不仅仅是等待</p>
</blockquote>
<blockquote>
<p>边等待，边计算</p>
</blockquote>
<h3 id="多线程，具体多少线程？"><a href="#多线程，具体多少线程？" class="headerlink" title="多线程，具体多少线程？"></a>多线程，具体多少线程？</h3><p>继续回想案例：计算一组 <code>y[i]=sin(x[i])</code></p>
<p>假设：计算耗时 20%，传输数据耗时 80%。</p>
<p>假如只有一个线程，<br>那么 cpu 有 80% 的时间在 stall（停顿），<br>也就是等待内存读写（load&#x2F;read memory）。</p>
<p>如果有 5 个线程，<br>那么在 1 个线程等待数据的 80%时间内，<br>剩下的 4 个线程可以完全占用 cpu，<br>当数据传输完毕，线程 1 回归计算操作，<br>cpu 利用率达到了 100%，<br>耗时缩短为原来的 20%，<br>从耗时结果上看，我们“隐藏了停顿”。</p>
<p>更多的线程不会带来更多的性能提升，<br>cpu 利用率已经到了 100%，<br>再增加线程反而会因为上下文切换，<br>导致耗时更多。</p>
<p class='item-img' data-src='/imgs/cs149/cs149-slide_069.jpg'><img src="/imgs/cs149/cs149-slide_069.jpg" alt="多少线程？"></p>
<p>那么，当计算耗时占比为 <code>x</code>（x∈(0, 1)）时，应该设置几个线程？</p>
<p>先想象一个线程在执行，<br>数据传输时间占比为：<code>1-x</code></p>
<p>为了占满（cover）等待时间，我们需要几个额外的线程呢？</p>
<p>那当然是 <code>(1-x)/x</code> 个啦。</p>
<p>所以总线程数是：<code>y = (1-x)/x + 1 = 1/x</code></p>
<blockquote>
<p><strong>结论</strong>：<br>当计算时间占比 <code>x</code>，线程数应设置为 <code>ceil(1/x)</code>。（ceil：向上取整）</p>
</blockquote>
<h3 id="硬件多线程"><a href="#硬件多线程" class="headerlink" title="硬件多线程"></a>硬件多线程</h3><p>Hardware-supported multi-threading<br>硬件支持的多线程</p>
<ul>
<li>硬件核心管理多个线程的执行上下文<ul>
<li>核心仍然拥有相同数量的 ALU 资源：多线程只有助于更有效地使用这些资源，在面对内存访问等高延迟操作时</li>
<li>处理器决定每个时刻运行哪一个线程</li>
</ul>
</li>
<li>交错多线程（也称时间多线程）<br>Interleaved multi-threading (a.k.a. temporal multi-threading)<ul>
<li>每个时钟，核心选择一个线程，并运行这个线程的一条指令，在核心的 ALUs 上</li>
</ul>
</li>
<li>同步多线程<br>Simultaneous multi-threading (SMT)<ul>
<li>每个时钟，核心从多个线程中选择多条指令在 ALUs 上运行</li>
<li>示例：英特尔超线程（Hyper-threading）（每个内核 2 个线程）</li>
</ul>
</li>
</ul>
<h3 id="你应该知道的一些术语"><a href="#你应该知道的一些术语" class="headerlink" title="你应该知道的一些术语"></a>你应该知道的一些术语</h3><ul>
<li>指令流 Instruction stream</li>
<li>多核处理器 Multi-core processor</li>
<li>SIMD 执行 SIMD execution</li>
<li>一致控制流 Coherent control flow</li>
<li>硬件多线程 Hardware multi-threading<ul>
<li>交错多线程 Interleaved multi-threading</li>
<li>同时多线程 Simultaneous multi-threading</li>
</ul>
</li>
</ul>
<h3 id="思考题："><a href="#思考题：" class="headerlink" title="思考题："></a>思考题：</h3><p>你写了一个 C 语言应用程序，生成了 2 个线程</p>
<p>你的应用程序运行在如下处理器上：</p>
<ul>
<li><p>2 个核心，每个核心 2 个执行上下文，每个时钟最多执行 （ ） 条指令，一条指令是 8 宽的 SIMD 指令。</p>
</li>
<li><p>问题 1：谁负责将应用程序的线程映射到处理器的线程执行上下文?</p>
<ul>
<li>答：操作系统（Operating system）</li>
</ul>
</li>
<li><p>问题 2：如果你来实现一个操作系统，那么如何将这 2 个线程分配给 4 个执行上下文？</p>
</li>
<li><p>问题 3：如果您的 C 程序派生了 5 个线程，如何分配给执行上下文？</p>
</li>
</ul>
<h1 id="其三：Multi-Core-Architecture-Part-II-ISPC-Programming-Abstractions"><a href="#其三：Multi-Core-Architecture-Part-II-ISPC-Programming-Abstractions" class="headerlink" title="其三：Multi-Core Architecture Part II + ISPC Programming Abstractions"></a>其三：Multi-Core Architecture Part II + ISPC Programming Abstractions</h1><blockquote>
<p>第三章：多核架构第二部分（延迟&#x2F;带宽 问题） + ISPC 编程概述</p>
</blockquote>
<h3 id="复习"><a href="#复习" class="headerlink" title="复习"></a>复习</h3><h4 id="回想：烹饪过程"><a href="#回想：烹饪过程" class="headerlink" title="回想：烹饪过程"></a>回想：烹饪过程</h4><blockquote>
<p>当你需要等待一件事，那你就去做另一件事</p>
</blockquote>
<p>多线程为什么能提高效率？<br>本质是通过 <strong>停顿时切换</strong>（<strong>switch on stall</strong>），<br>也就是在停顿时干别的事，<br>消除了停顿时间。</p>
<p>在停顿、等待时，切换任务，去干别的事情，<br>保证计算机资源充分利用，<br>“压榨硬件性能”、“物尽其用”。</p>
<h2 id="现代处理器"><a href="#现代处理器" class="headerlink" title="现代处理器"></a>现代处理器</h2><h4 id="例子：Kayvons-虚构的多核芯片"><a href="#例子：Kayvons-虚构的多核芯片" class="headerlink" title="例子：Kayvons 虚构的多核芯片"></a>例子：Kayvons 虚构的多核芯片</h4><p>现在，我们假想有一个处理器，性能参数如下：</p>
<ul>
<li>16 核心</li>
<li>8 SIMD ALUs 每核心（共 128）</li>
<li>4 线程 每核心（共 64 线程）（硬件多线程）</li>
<li>16 最大并行（simultaneous）指令流</li>
<li>64 最大并发（concurrent）指令流</li>
<li>那么需要创建 512 个任务（task），如果你要完全“隐藏”延迟</li>
</ul>
<h4 id="例子：Intel-Skylake-Kaby-Lake-core"><a href="#例子：Intel-Skylake-Kaby-Lake-core" class="headerlink" title="例子：Intel Skylake&#x2F;Kaby Lake core"></a>例子：Intel Skylake&#x2F;Kaby Lake core</h4><blockquote>
<ul>
<li>Skylake 微架构（第六代 Intel Core）</li>
<li>发布时间：2015 年</li>
<li>制程工艺：采用 14nm 工艺。</li>
<li>支持 DDR4 内存：首次支持 DDR4 内存（同时兼容 DDR3L），大幅提升内存带宽。</li>
<li>微架构更新：<ul>
<li>执行单元优化：增加了调度器和缓冲区大小，提升多线程性能。</li>
<li>分支预测增强：改进了分支预测算法，减少错误预测的开销。</li>
<li>更深的流水线：更高的指令并行性，使得单核性能（IPC）显著提升。</li>
<li>三级缓存改进：更高效的共享缓存，提高多核间的数据访问速度。</li>
</ul>
</li>
</ul>
</blockquote>
<p class='item-img' data-src='/imgs/cs149/cs149-slide_095.jpg'><img src="/imgs/cs149/cs149-slide_095.jpg" alt="Intel Skylake/Kaby Lake core"><br>这张图是 Intel Skylake&#x2F;Kaby Lake 架构 CPU 的其中一个核心 Core 0.<br>双路多线程核心（2 线程）。<br>每个核心最多可以同时运行 4 个独立的标量指令和 3 个 8 宽的向量指令<br>（最多 2 个向量相乘或 3 个向量相加）</p>
<blockquote>
<p>学生：双线程可以同时运行？但我们仍然需要按顺序取指令？额外的取指器&#x2F;解码器是如何起作用的？</p>
<p>老师（Kayvon）：宽松地讲，可以想象这群取值器&#x2F;解码器看作一个高级的取值和解码单元（”fancy fetch and decode unit”），它们有能力把“一堆指令”塞满“一堆执行单元（a bunch of execution units）”，取指器&#x2F;解码器的操作是，从 Thread0 中找一些指令，在 Thread1 中找到一些指令，然后我有很多黄框框（ALUs）需要被填满，我要做的就是尽可能地用指令填满这些黄框框，来充分利用 CPU 的计算性能（ALUs）。</p>
<p>“every thing here composes”，<br>在这个芯片上，一切都组合在了一起<br>这个芯片是一个：</p>
<ul>
<li>超标量芯片（Superscalar）</li>
<li>SIMD 芯片</li>
<li>硬件同时多线程芯片（Intel 超线程）</li>
<li>多核芯片</li>
</ul>
</blockquote>
<p><strong>我的补充</strong>：</p>
<ul>
<li>然而有的指令是标量，有的是向量，有的指令有依赖关系，有的指令可以并行执行但间隔太远，它们并不一定能并行，这取决于程序。</li>
<li>程序（指令流）并不会按顺序执行，因为很可能你写的程序编译后，可并行性差得要命！因此，现代处理器会乱序执行。</li>
<li>早期超线程技术中，会有缓存问题。比如线程 1 修改了线程 2 的缓存，导致缓存失效需要重新读取。有时，减少线程数会有利于应用程序更好地运行。</li>
<li>即使是目前，超线程技术仍存在安全问题。因此，一些安全专家建议全面禁止超线程。</li>
</ul>
<h4 id="例子：NVIDIA-V100-GPU"><a href="#例子：NVIDIA-V100-GPU" class="headerlink" title="例子：NVIDIA V100 GPU"></a>例子：NVIDIA V100 GPU</h4><ul>
<li>共 80 个“SM（Streaming Multiprocessor）” 核心</li>
<li>每个 SM 有 64 个 warp 执行上下文</li>
<li>SIMD ALUs 位宽为 16，启动 2 个时钟周期后为 32</li>
<li><code>64 \* 32 = 2048</code> 最大数据并发量&#x2F;SM</li>
</ul>
<p><code>80 \* 2048 = 163840</code> 最大数据并发量（每个时钟周期）<br>（另注：不是并行，并行量略低）</p>
<blockquote>
<p>[!NOTE]<br>并行计算性能为：<br>FP32 性能 &#x3D; CUDA 核心数 × 时钟频率 × 每个核心每周期的运算</p>
<p>FP32 性能 &#x3D; <code>5120 × 1.53GHz × 2 = 15.7 TFLOPS</code> &#x3D; 15.7 * 10^12 FLOPS</p>
<p>大约每秒 16 万亿次 32 位浮点运算</p>
</blockquote>
<p>仅在硬件级别，就提供了 16 万的并发量。<br>这还没有考虑，<br>实际任务的计算耗时与数据传输耗时占比，<br>为了完全覆盖停顿时间，<br>所需要的额外线程数。<br>如果仍然使用计算 sinx 的任务来占满这个芯片，<br>除非你有成千上万的数据要处理，<br>否则还是别费劲了。<br>这就是为什么一个小型 DNN 在大型 GPU 上运行不佳。</p>
<blockquote>
<p>因为我们没有足够多的任务去塞满它</p>
</blockquote>
<h2 id="如何高效利用现代处理器？"><a href="#如何高效利用现代处理器？" class="headerlink" title="如何高效利用现代处理器？"></a>如何高效利用现代处理器？</h2><p>为了高效地利用现代并行处理器，必须：</p>
<ol>
<li>有足够多的并行工作来利用所有可用的执行单元<br>（跨多个核心和每个核心的多个执行单元）</li>
<li>并行工作任务组必须要求相同的指令顺序<br>（利用 SIMD 执行）</li>
<li>（软件要向硬件）暴露比处理器 ALUs 数更多的并行工作数目，来保证并发能够隐藏内存停滞。</li>
</ol>
<h3 id="多线程的另一个作用：塞满计算单元"><a href="#多线程的另一个作用：塞满计算单元" class="headerlink" title="多线程的另一个作用：塞满计算单元"></a>多线程的另一个作用：塞满计算单元</h3><p>继续设想一个处理器，<br>他的 ALUs 支持 4 个标量指令和 3 个向量指令。</p>
<p>假如单线程运行，<br>硬件最多只能发现 2 个标量可以并行<br>（或者 2 个向量指令，<br>或者 1 个标量 1 个向量），<br>因为其他指令有依赖关系或者相距过远无法并行。</p>
<p>当双线程运行，<br>硬件可能就会在 thread0 找到 2 个标量指令，<br>在 thread1 找到 2 个向量指令，<br>然后同时运行它们。</p>
<p>当线程数来到 4 个，<br>处理器很聪明的找到了 4 个标量指令和 3 个向量指令，<br>然后把它们塞满 ALUs，<br>这样，这个虚构处理器就达到了最高的利用率。</p>
<p>我们就知道了<strong>乱序执行（指令重排）</strong>的好处之一：<br>原本由于相距过远无法并行的指令，<br>打乱顺序后紧挨在了一起，<br>就可以并行了<br>（在没有依赖关系的条件下）。</p>
<p><strong>那如果有依赖关系呢？</strong></p>
<ul>
<li>内存屏障：处理器会通过内存屏障（读、写、全屏障）等技术确保逻辑无误。</li>
<li>寄存器重命名：通过寄存器重命名技术，处理器可以消除伪依赖关系，从而提高并行度。</li>
</ul>
<blockquote>
<p>[挖坑]<br>Kayvon 老师：但是 AMD 和 NVIDIA 的 GPU 工作方式略有不同</p>
</blockquote>
<h3 id="GPU-SIMT-Single-Instruction-Multiple-Thread"><a href="#GPU-SIMT-Single-Instruction-Multiple-Thread" class="headerlink" title="GPU SIMT(Single Instruction Multiple Thread)"></a>GPU SIMT(Single Instruction Multiple Thread)</h3><p>大部分现代 GPU 永远都只会编译生成<br><strong>标量指令（scalar instruction）</strong></p>
<p>GPU 核会检测硬件线程的执行指令是否相同<br>（通过判断程序计数器（pc）），<br>如果相同，就用一个向量指令来代替原本的多个相同的标量指令。</p>
<p>假设一个 GPU 核心有一个 8 位宽的向量 ALUs<br>（可以同时计算八个操作）。<br>假设有 8 个线程，<br>每当这 8 个线程的程序计数器（pc）相同，<br>那么就在这 8 位宽的向量运算器上<strong>同时</strong>运行这 8 个指令<br>这与编译了一个 8 位宽 SIMD 向量操作效果相同。</p>
<p>那么如果有 7 个线程的 pc 相同，仅有一个线程不同呢？</p>
<p>那个线程会被 “masked off”（屏蔽）。（回想：第二讲中的<a href="#%E6%9D%A1%E4%BB%B6%E5%88%86%E6%94%AF">条件分支</a>）</p>
<h3 id="回想：思考题"><a href="#回想：思考题" class="headerlink" title="回想：思考题"></a>回想：思考题</h3><p>你写了一个 C 语言应用程序，生成了 2 个线程</p>
<p>你的应用程序运行在如下处理器上：</p>
<ul>
<li><p>2 个核心，每个核心 2 个执行上下文，每个时钟最多执行 （ ） 条指令，一条指令是 8 宽的 SIMD 指令。</p>
</li>
<li><p>问题 1：谁负责将应用程序的线程映射到处理器的线程执行上下文?</p>
<ul>
<li>答：操作系统（Operating system）</li>
</ul>
</li>
<li><p>问题 2：如果你来实现一个操作系统，那么如何将这 2 个线程分配给 4 个执行上下文？</p>
</li>
<li><p>问题 3：如果您的 C 程序派生了 5 个线程，如何分配给执行上下文？</p>
<ul>
<li>如果是两个截然不同的线程，把他们都分配到一个核上显然是不太合适的</li>
<li>那如果这俩线程需要访问相同的数据呢？想要共享缓存或者其他资源呢？答案可能恰恰相反</li>
</ul>
</li>
</ul>
<blockquote>
<p>学生：现在我们有多个执行上下文，那么如何决定是使用硬件多线程还是使用超标量架构？</p>
<p>Kayvon：这是芯片（chip）实现的细节，不是操作系统的任务。</p>
<p>操作系统会说：“hey，chip！请你给我在 core1 上运行 thread3。”</p>
<p>芯片会在每个时钟周期，根据自己拥有的执行上下文，决定执行哪些指令，如何执行，这个决策每秒数亿次，都发生在硬件中。</p>
<p>操作系统还可能这样说：“你要 8 个线程来塞满你对吧。好，这是我从 1000 个准备好的用户线程中挑选的 8 个，你先给我执行一下子。”</p>
<p>这就是操作系统级别的<strong>上下文切换</strong>。<br>这种操作大约耗时十万个 cycles（时钟周期），<br>且发生频率很低。</p>
</blockquote>
<blockquote>
<p>学生：有没有办法让编译器强制执行一些行为？</p>
<p>Kayvon：是的。现代操作系统有 APIs，可以指定一个线程在特定的执行上下文中运行。</p>
<p>学生追问：哦不，只是强制执行超标量架构的与否。比如说我就是不想乱序执行，不想让多个运算器协作</p>
<p>Kayvon：据我所知，这不是你可以过多干预的事。<br>当然，你可以说你想关闭超线程这一功能，这很简单。<br>如果你要干预处理器调度细节，据我所知，我并不清楚你有多少控制权。<br>也许在 BIOS 级别可以，但在标准 OS 中可能不行。</p>
</blockquote>
<h3 id="思考题：C-i-A-i-B-i"><a href="#思考题：C-i-A-i-B-i" class="headerlink" title="思考题：C[i] &#x3D; A[i] * B[i]"></a>思考题：C[i] &#x3D; A[i] * B[i]</h3><p>假如有两个非常长的数组，成千上万。<br>那么，它们之间的加法或者乘法计算，<br>并将结果存入 C 数组中，<br>这个计算是否适合在现代的面向吞吐量的并行处理器上执行？</p>
<p>你会觉得这个向量运算太适合在现代处理器上执行了，<br>现代处理器不就是向量优化的嘛？</p>
<p>但实际上，这可能是一个最糟糕的程序，<br>在现代处理器上，<br>然后你每天都会运行它。</p>
<p>为什么？</p>
<p>想象一下，这些数据存放在哪里？<br>硬盘上。</p>
<ul>
<li>最新的闪存固态硬盘，传输速率也不超过 64GB 每秒（PCIe 5.0）</li>
<li>Nvidia V100 的计算性能大致为 16 万亿次浮点运算每秒。</li>
</ul>
<p>假如我们正好需要算 16 万亿个浮点运算。<br>也就是说，我们有 <code>2\*16 = 32</code> 万亿个数字存放在硬盘上，<br>需要花费大量时间（<code>4*16TB / 64GBps = 8ks = 2.3小时</code>）搬运到我们的 V100 上，<br>然后 V100 花了一秒就算完了，<br>接着我们又要花 2 个小时把数据搬回去。</p>
<p>是什么限制了并行计算效率？</p>
<p>带宽。</p>
<h2 id="带宽-Bandwidth"><a href="#带宽-Bandwidth" class="headerlink" title="带宽 Bandwidth"></a>带宽 Bandwidth</h2><h4 id="101-公路"><a href="#101-公路" class="headerlink" title="101 公路"></a>101 公路</h4><p>假设 101 号公路连接着旧金山和斯坦福，</p>
<ul>
<li>为了简便运算，全长约为 50 km。</li>
<li>假设我们都以 100 km&#x2F;h 的速度行驶。</li>
</ul>
<p>问题 1：通行（延迟（Latency））时间是多少？</p>
<p>答：<strong>半个小时</strong></p>
<p>为了保证安全，比如防止追尾，我们添加一条新的规则（初版）:</p>
<ul>
<li>只允许一辆车占用这条公路.</li>
</ul>
<p>问题 2：那么每小时吞吐量为？</p>
<p>答：每小时 2 辆车。</p>
<p>那么如何优化吞吐量呢？</p>
<ul>
<li>方法 1：开快点。<ul>
<li>如果提速到 200km&#x2F;h，就可以每小时通行 4 辆车！</li>
</ul>
</li>
<li>方法 2：多建车道。<ul>
<li>把 101 公路增加到 4 车道，每小时就能通行 8 辆车！</li>
</ul>
</li>
<li>方法 3：修改规则，允许同一车道开多辆车。<ul>
<li>允许车间隔至少 1km，同时占用同一车道，既保证了安全，又增加了吞吐量。现在，每小时可以通行 100 辆车！</li>
</ul>
</li>
</ul>
<h3 id="内存带宽"><a href="#内存带宽" class="headerlink" title="内存带宽"></a>内存带宽</h3><blockquote>
<p>内存带宽是一个速率 – 单位时间内完成多少事情。</p>
<p>Memory bandwidth is a rate<br>– how many things are completed per unit time.</p>
</blockquote>
<p>假设我现在有一个内存到处理器的带宽例子：</p>
<p>原始的：</p>
<ul>
<li>假设我每秒发射 4 个方块</li>
<li>那么现在带宽就是：4 items&#x2F;sec</li>
</ul>
<p>带宽增加的：</p>
<ul>
<li>我可以通过一次发射 2 个项目来增大带宽</li>
<li>现在带宽来到了：<code>2 * 4 = 8</code> items&#x2F;sec</li>
</ul>
<p>我们会发现，带宽和延迟成为了不同的两个概念。<br>我们会在之后多次提到 <strong>流水线</strong> 这个词，<br>就像在 101 公路上多车道塞满车运行一样，<br><strong>吞吐量</strong> 或者说 <strong>带宽</strong> 是可以远远超出 <strong>延迟</strong> 的限制的</p>
<blockquote>
<p>带宽 !&#x3D; 延迟</p>
</blockquote>
<h4 id="例子：洗衣服"><a href="#例子：洗衣服" class="headerlink" title="例子：洗衣服"></a>例子：洗衣服</h4><p>操作：洗衣服</p>
<ol>
<li>洗（洗衣机） 45 min</li>
<li>烘干（烘干机） 60 min</li>
<li>折叠（大学生） 15 min</li>
</ol>
<p>在这个例子中，洗衣服的 <strong>延迟</strong> 是 2 小时，<br>但吞吐量是多少呢？</p>
<p>如果我们只洗 2kg 衣服（假设洗衣机容量是 2kg 衣服），<br>那吞吐量就是每 1 kg&#x2F;h。</p>
<p>如果我们有 4kg 衣服要洗呢？</p>
<p>你可以再买一套洗衣机+烘干机，<br>再叫上你的好伙计，<br>然后并行进行两堆衣服的洗烘叠三步骤。<br>最后骄傲地说：“嘿，瞧，我们把效率提高到了 2 倍！”</p>
<p>我想，傻子都不会这么做。</p>
<p>假如有很多堆衣服要洗，正常人都会这样做：<br>在第一堆衣服洗完烘干后，<br>把第二堆衣服（在洗衣机里洗好的）送进烘干机，<br>把第三堆衣服送进洗衣机洗。</p>
<blockquote>
<p>因为，我们始终都想要填满 <strong>流水线</strong> 上的每一个单元。</p>
</blockquote>
<p>所以，我们不希望 cpu 闲置，ALUs 闲置，或者很多线程在等待执行。当然，我们也不希望洗衣机或烘干机在洗一堆衣服时处于闲置状态。</p>
<p>那么，流水线工作的洗衣机和烘干机，<br>整体系统的吞吐量（Throughput）是多少呢？<br class='item-img' data-src='https://gfxcourses.stanford.edu/cs149/fall24content/media/multicore2/images/slide_015.jpg'><img src="https://gfxcourses.stanford.edu/cs149/fall24content/media/multicore2/images/slide_015.jpg" alt="pipelining laundy"></p>
<p>可以看到，烘干机一直在拖后腿，<br>洗衣机早就洗好了，<br>他们的差距越来越大，<br>系统吞吐量不会超过 1 load&#x2F;hour，<br>这也正是烘干机的工作时间 – <strong>1 hour</strong>。</p>
<blockquote>
<p><strong>短板效应</strong><br>流水线中最慢的单元限制最大吞吐量</p>
</blockquote>
<p>试想一下，如果计算机各个单元也这样不匹配，<br>数据就会像衣服一样，<br>逐渐“堆满”有限的缓冲区（烘干机的机体上&#x2F;计算机的缓冲区），<br>直到挤爆缓冲区，把电脑卡死，<br>这是非常荒谬的。</p>
<p>回想计组中的指令流水线：取指、译码、加减乘除、读取、写回。<br>在计算机组成中，我们的做法是：更多的洗衣机，更少的烘干机<br>（更多的 ALUs，更少的取指器）</p>
<p>这个例子中，洗衣机和烘干机的速度比例是 <code>1/45 : 1/60 = 4:3</code> ，<br>所以我们最好用速度的反比 <code>3:4</code> 的比例来配置洗衣机和烘干机的数量，以防止衣服堆积在中间。</p>
<h4 id="回想：案例：C-i-A-i-B-i"><a href="#回想：案例：C-i-A-i-B-i" class="headerlink" title="回想：案例：C[i] = A[i] * B[i]"></a>回想：案例：<code>C[i] = A[i] * B[i]</code></h4><p>现在，让我们回到计算机的视角：<br>处理器很快，<br>但内存带宽限制了系统的吞吐量。<br>内存带宽就像那个烘干机，一直拖后腿。<br>最先进的 NVlink 传输速率是 900GB&#x2F;s。</p>
<p>假如在 V100 上运行这个程序，<br>每个数学运算都需要 12 个字节（3 个 4 字节的浮点数），<br>V100 的每秒浮点运算次数约为 16 万亿次，<br>每秒钟，我们需要大约 100TB 的数据，<br>但最先进的 NVlink 技术也只能达到 900GB&#x2F;s 的传输速率。</p>
<p>可以理解为：你的洗衣机比烘干机块一百倍。</p>
<p>所以，这个程序在 V100 上运行的效率是 **小于 1%**。</p>
<p>此时，缓存没有用，缓存只在重复读取时有用。</p>
<blockquote>
<p>如果你只是想做这样的一次性简单向量运算，那么面对 1% 的超低效率，你无能为力。</p>
<p>除了改变你的程序，或者等待更快的内存系统出现，你别无选择。</p>
</blockquote>
<blockquote>
<p>这个程序是 <strong>带宽限制</strong> 的（bandwidth limited）。</p>
</blockquote>
<p>那能不能增加“车道”呢？</p>
<p>很遗憾，就像现实中都很少有 8 车道一样，专家们也受到物理上的限制和系统总线的限制，64 位地址已经相当复杂，再加车道可能难以与其他部件协调。NVlink 已经很快了，但造价昂贵，得不偿失，只是跟处理器比起来，内存带宽确实相对太慢了。计算机是一个整体系统，<strong>整体大于局部之和</strong>。</p>
<blockquote>
<p>学生：既然如此，V100 为什么要造出一百倍的计算单元来？</p>
<p>Kayvon：因为大部分深度学习并不是简单的一次性向量运算，而是 <strong>读取一次，计算多次</strong>。</p>
</blockquote>
<h2 id="ISCP"><a href="#ISCP" class="headerlink" title="ISCP"></a>ISCP</h2><blockquote>
<p>ISPC 全称是 Intel SPMD Program Compiler，它是由 Intel 开发的一种编程工具，用于编写单指令多数据（SPMD，Single Program Multiple Data） 风格的并行程序。它特别适合在现代 CPU 和 GPU 上运行高性能并行计算任务。</p>
</blockquote>
<blockquote>
<p>这是一种相当冷门的语言，<br>冷门到你在 Github 和 Stack Overflow 上找不到几个相关东西。<br>使用它的人数可能就是本课程的学习人数乘以开课年限，再加上几百个英特尔相关方向的从业者。</p>
</blockquote>
<ul>
<li>ISPC：Intel SPMD Program Compiler</li>
<li>SPMD：Single Program Multiple Data 单程序多数据</li>
</ul>
<hr>
<ul>
<li><a target="_blank" rel="noopener" href="https://ispc.github.io/">https://ispc.github.io/</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/ispc/ispc">https://github.com/ispc/ispc</a></li>
<li><a target="_blank" rel="noopener" href="https://pharr.org/matt/blog/2018/04/30/ispc-all">https://pharr.org/matt/blog/2018/04/30/ispc-all</a><blockquote>
<p>为什么 C++ 不够快？为什么要设计 ISPC？</p>
</blockquote>
</li>
</ul>
<h3 id="ISPC-重写-sinx"><a href="#ISPC-重写-sinx" class="headerlink" title="ISPC 重写 sinx()"></a>ISPC 重写 sinx()</h3><p>回想：一般的 sinx()</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-comment">// sinx.h</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">sinx</span><span class="hljs-params">(<span class="hljs-type">int</span> N, <span class="hljs-type">int</span> terms, <span class="hljs-type">float</span>* x, <span class="hljs-type">float</span>* result)</span><br>&#123;<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i=<span class="hljs-number">0</span>; i&lt;N; i++)<br>    &#123;<br>        <span class="hljs-type">float</span> value = x[i];<br>        <span class="hljs-type">float</span> numer = x[i] * x[i] * x[i];<br>        <span class="hljs-type">int</span> denom = <span class="hljs-number">6</span>; <span class="hljs-comment">// 3!</span><br>        <span class="hljs-type">int</span> sign = <span class="hljs-number">-1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j=<span class="hljs-number">1</span>; j&lt;=terms; j++)<br>        &#123;<br>            value += sign * numer / denom;<br>            numer *= x[i] * x[i];<br>            denom *= (<span class="hljs-number">2</span>*j + <span class="hljs-number">2</span>) * (<span class="hljs-number">2</span>*j + <span class="hljs-number">3</span>);<br>            sign *= <span class="hljs-number">-1</span>;<br>        &#125;<br>      result[i] = value;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>它的主函数可能是</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs C:main.cpp">// main.cpp<br>#include &quot;sinx.h&quot;<br><br>int main(int argc, void** argv)<br>&#123;<br>  int N = 1024;<br>  int terms = 5;<br>  float* x = new float[N];<br>  float* result = new float[N];<br><br>  // initialize x here<br><br>  sinx(N, terms, x, result);<br><br>  return 0;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>现在，看看如何用 ISPC 重写这个程序<br class='item-img' data-src='https://gfxcourses.stanford.edu/cs149/fall24content/media/multicore2/images/slide_032.jpg'><img src="https://gfxcourses.stanford.edu/cs149/fall24content/media/multicore2/images/slide_032.jpg" alt="ISPC-sinx"></p>
<p>当调用 ispc_sinx()函数时，<br>它并不像常规 C 语言程序一样（调用-返回），<br>它的大致流程是：</p>
<ol>
<li>调用 ISPC 函数，生成一群 <code>程序实例（program instances）</code>（不是线程 thread）<ul>
<li>程序实例的个数由 <code>programCount</code> （程序计数）决定</li>
<li>每个程序实例的 <code>programIndex</code>（程序索引）是不同的，以此来区分不同程序实例的任务</li>
</ul>
</li>
<li>所有实例同时运行 ISPC 代码</li>
<li>每个实例都有自己的局部变量副本<br>（代码中的蓝色变量，稍后我们将讨论“uniform”）</li>
<li>返回时，所有实例都完事了</li>
</ol>
<blockquote>
<p>问题：假如 <code>programCount</code> （程序计数）为 8，也就是 8 个程序同时运行，编号为 0 到 7。那么请问，每个程序（比如程序编号为 j 的程序），做哪些元素的运算？</p>
<p>答：编号为 j 的程序，做 <code>sin(x[i])</code>，其中<code>i mod j = 0</code></p>
</blockquote>
<p>想象一下希尔排序，就是不断变换步长进行插入排序，<br>其中每一轮插入排序做的工作，<br>就是现在这个 ispc 派生的 8 个程序实例所做的工作。<br>它们在空间上（数组上）是 <strong>交错执行</strong> 的。</p>
<p class='item-img' data-src='https://gfxcourses.stanford.edu/cs149/fall24content/media/multicore2/images/slide_035.jpg'><img src="https://gfxcourses.stanford.edu/cs149/fall24content/media/multicore2/images/slide_035.jpg" alt="ISPC交错执行"></p>
<p>另一种方式则是分块执行</p>
<p class='item-img' data-src='https://gfxcourses.stanford.edu/cs149/fall24content/media/multicore2/images/slide_037.jpg'><img src="https://gfxcourses.stanford.edu/cs149/fall24content/media/multicore2/images/slide_037.jpg" alt="ISPC-sinx-version2"></p>
<p class='item-img' data-src='https://gfxcourses.stanford.edu/cs149/fall24content/media/multicore2/images/slide_038.jpg'><img src="https://gfxcourses.stanford.edu/cs149/fall24content/media/multicore2/images/slide_038.jpg" alt="ISPC分块执行"></p>
<p>我们有多种方式实现 SPMD，<br>但如何分配这些派生的 <code>Program Instance</code>，<br>是最好的方式呢？<br>因为 <code>Program Instance</code> 只是 Intel 提出的一个概念罢了，<br>具体到硬件还是要线程来干。</p>
<p>分配程序实例的 4 种方式：<br class='item-img' data-src='https://gfxcourses.stanford.edu/cs149/fall24content/media/multicore2/images/slide_042.jpg'><img src="https://gfxcourses.stanford.edu/cs149/fall24content/media/multicore2/images/slide_042.jpg" alt="分配程序实例的4种方式"></p>
<blockquote>
<p>Kayvon：I don’t care.</p>
</blockquote>
<p>我们不需要关心具体实现的细节，<br>我们只需要 for 循环迭代一个东西，<br>剩下的，交给编译器和硬件。</p>
<blockquote>
<p>这就是为什么 for 循环非常快的原因之一。</p>
<p>其他原因？Cache（缓存）</p>
</blockquote>
<div id="paginator"></div></div><div id="post-footer"><div id="pages" style="justify-content: flex-end"><div class="footer-link" style="width: 50%;right:1px;border-left:1px #fe2 solid"><a href="/2025/01/16/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E3%80%8A%E6%95%99%E5%85%BB%E7%9A%84%E8%BF%B7%E6%80%9D%E3%80%8B/">读书笔记-《教养的迷思》 Prev →</a></div></div></div></div><div class="bottom-btn"><div><a class="i-top" id="to-top" onClick="scrolls.scrolltop();" title="To Top" style="opacity: 0; display: none;">∧ </a><a class="i-index" id="to-index" href="#toc-div" title="To Catalog">≡</a><a class="i-color" id="color-mode" onClick="colorMode.change()" title="Change Theme"></a></div></div></article><aside><div id="about"><a href="/" id="logo"><img src="https://ak.hypergryph.com/assets/index/images/ak/pc/faction/1.png" alt="Logo"></a><h1 id="Dr"><a href="/">wwnao</a></h1><div id="description"><p>友利奈绪-勿忘我的博客</p></div><div id="social-links"><a class="social" target="_blank" rel="noopener" href="https://github.com/tomorinao-www"><i class="fab fa-github" alt="GitHub"></i></a><a class="social" target="_blank" rel="noopener" href="https://space.bilibili.com/186677485"><i class="fa-brands fa-bilibili" alt="BiliBili"></i></a></div></div><div id="aside-block"><div id="toc-div"><h1>Catalog</h1><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#CS149-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0"><span class="toc-number">1.</span> <span class="toc-text">CS149-并行计算-斯坦福大学-学习笔记</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B6%E4%B8%80%EF%BC%9AWhy-Parallelism-Why-Efficiency"><span class="toc-number">2.</span> <span class="toc-text">其一：Why Parallelism? Why Efficiency?</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#demo1%EF%BC%9A%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%B9%B6%E8%A1%8C%E7%A8%8B%E5%BA%8F"><span class="toc-number">2.1.</span> <span class="toc-text">demo1：第一个并行程序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A8%8B%E5%BA%8F%EF%BC%9F-What-is-a-computer-program"><span class="toc-number">2.2.</span> <span class="toc-text">什么是计算机程序？ What is a computer program ?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E5%99%A8%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F-What-does-a-processor-do"><span class="toc-number">2.3.</span> <span class="toc-text">处理器做了什么？ What does a processor do ?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%EF%BC%9Aa-x-x-y-y-z-z"><span class="toc-number">2.4.</span> <span class="toc-text">案例：a &#x3D; x * x + y * y + z * z</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%EF%BC%88ChatGPT%EF%BC%89"><span class="toc-number">2.5.</span> <span class="toc-text">编译优化（ChatGPT）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AF%84%E5%AD%98%E5%99%A8%E6%9C%80%E5%A4%9A%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%88%99%EF%BC%88Maximizing-Register-Usage%EF%BC%89"><span class="toc-number">2.5.1.</span> <span class="toc-text">1. 寄存器最多使用原则（Maximizing Register Usage）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%AF%84%E5%AD%98%E5%99%A8%E5%88%86%E9%85%8D%E5%92%8C%E5%AF%84%E5%AD%98%E5%99%A8%E9%87%8D%E5%91%BD%E5%90%8D"><span class="toc-number">2.5.2.</span> <span class="toc-text">2. 寄存器分配和寄存器重命名</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E4%BC%98%E5%8C%96"><span class="toc-number">2.5.3.</span> <span class="toc-text">3. 局部变量优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%86%85%E8%81%94%E6%89%A9%E5%B1%95%EF%BC%88Inlining%EF%BC%89"><span class="toc-number">2.5.4.</span> <span class="toc-text">4. 内联扩展（Inlining）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%BE%AA%E7%8E%AF%E4%BC%98%E5%8C%96%EF%BC%88Loop-Optimization%EF%BC%89"><span class="toc-number">2.5.5.</span> <span class="toc-text">5. 循环优化（Loop Optimization）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%AF%84%E5%AD%98%E5%99%A8%E5%8E%8B%E5%8A%9B%E5%92%8C%E6%BA%A2%E5%87%BA%EF%BC%88Register-Pressure-and-Spill%EF%BC%89"><span class="toc-number">2.5.6.</span> <span class="toc-text">6. 寄存器压力和溢出（Register Pressure and Spill）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E8%87%AA%E5%8A%A8%E5%90%91%E9%87%8F%E5%8C%96"><span class="toc-number">2.5.7.</span> <span class="toc-text">7. 自动向量化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98%E5%92%8C%E6%95%B0%E6%8D%AE%E5%B1%80%E9%83%A8%E6%80%A7"><span class="toc-number">2.5.8.</span> <span class="toc-text">8. 多级缓存和数据局部性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%92%8C%E5%A4%9A%E6%A0%B8%E4%BC%98%E5%8C%96"><span class="toc-number">2.5.9.</span> <span class="toc-text">9. 并行计算和多核优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-%E6%8C%87%E4%BB%A4%E7%BA%A7%E5%B9%B6%E8%A1%8C%E6%80%A7%EF%BC%88ILP%EF%BC%89%E4%BC%98%E5%8C%96"><span class="toc-number">2.5.10.</span> <span class="toc-text">10. 指令级并行性（ILP）优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">2.5.11.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B6%E4%BA%8C%EF%BC%9AA-Modern-Muti-Core-Processor"><span class="toc-number">3.</span> <span class="toc-text">其二：A Modern Muti-Core Processor</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%EF%BC%9A%E8%AE%A1%E7%AE%97-y-i-sin-x-i"><span class="toc-number">3.1.</span> <span class="toc-text">案例：计算 y[i]&#x3D;sin(x[i])</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%AB%98%E7%BB%B4%E5%BA%A6%E5%B9%B6%E8%A1%8C%E5%8C%96%EF%BC%88%E8%B0%83%E7%94%A8%E6%96%B9%E5%B9%B6%E8%A1%8C%EF%BC%89"><span class="toc-number">3.1.0.1.</span> <span class="toc-text">高维度并行化（调用方并行）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%91%E9%87%8F%E7%BC%96%E7%A8%8B%EF%BC%88%E5%BA%95%E5%B1%82%E5%B9%B6%E8%A1%8C%EF%BC%89"><span class="toc-number">3.1.0.2.</span> <span class="toc-text">向量编程（底层并行）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E5%88%86%E6%94%AF"><span class="toc-number">3.1.1.</span> <span class="toc-text">条件分支</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%B0%E4%BB%A3%E5%A4%9A%E6%A0%B8%E5%A4%84%E7%90%86%E5%99%A8"><span class="toc-number">3.2.</span> <span class="toc-text">现代多核处理器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%A7%8D%E4%B8%8D%E5%90%8C%E5%BD%A2%E5%BC%8F%E7%9A%84%E5%B9%B6%E8%A1%8C%E6%89%A7%E8%A1%8C"><span class="toc-number">3.2.1.</span> <span class="toc-text">3 种不同形式的并行执行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%B0%E4%BB%A3%E5%A4%9A%E6%A0%B8%E5%A4%84%E7%90%86%E5%99%A8-1"><span class="toc-number">3.2.2.</span> <span class="toc-text">现代多核处理器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%EF%BC%9A%E8%AE%BF%E9%97%AE%E5%86%85%E5%AD%98%EF%BC%88Part2%EF%BC%9Aaccessing-memory%EF%BC%89"><span class="toc-number">3.3.</span> <span class="toc-text">第二部分：访问内存（Part2：accessing memory）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9E%E6%83%B3%EF%BC%9A%E9%9D%9E%E5%B8%B8%E9%95%BF%E7%9A%84%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE%E5%BB%B6%E8%BF%9F"><span class="toc-number">3.3.0.1.</span> <span class="toc-text">回想：非常长的数据访问延迟</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9E%E6%83%B3%EF%BC%9A%E7%BC%93%E5%AD%98%E6%9C%AA%E5%91%BD%E4%B8%AD"><span class="toc-number">3.3.0.2.</span> <span class="toc-text">回想：缓存未命中</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9E%E6%83%B3%EF%BC%9A%E6%95%B0%E6%8D%AE%E9%A2%84%E5%8F%96"><span class="toc-number">3.3.0.3.</span> <span class="toc-text">回想：数据预取</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC-3-%E7%A7%8D%E6%96%B9%E6%B3%95%EF%BC%9A%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E9%9A%90%E8%97%8F%E5%81%9C%E9%A1%BF%EF%BC%88hide-stall%EF%BC%89"><span class="toc-number">3.3.1.</span> <span class="toc-text">第 3 种方法：用多线程隐藏停顿（hide stall）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E7%BA%BF%E7%A8%8B%EF%BC%8C%E5%85%B7%E4%BD%93%E5%A4%9A%E5%B0%91%E7%BA%BF%E7%A8%8B%EF%BC%9F"><span class="toc-number">3.3.2.</span> <span class="toc-text">多线程，具体多少线程？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A1%AC%E4%BB%B6%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="toc-number">3.3.3.</span> <span class="toc-text">硬件多线程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%A0%E5%BA%94%E8%AF%A5%E7%9F%A5%E9%81%93%E7%9A%84%E4%B8%80%E4%BA%9B%E6%9C%AF%E8%AF%AD"><span class="toc-number">3.3.4.</span> <span class="toc-text">你应该知道的一些术语</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98%EF%BC%9A"><span class="toc-number">3.3.5.</span> <span class="toc-text">思考题：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B6%E4%B8%89%EF%BC%9AMulti-Core-Architecture-Part-II-ISPC-Programming-Abstractions"><span class="toc-number">4.</span> <span class="toc-text">其三：Multi-Core Architecture Part II + ISPC Programming Abstractions</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%8D%E4%B9%A0"><span class="toc-number">4.0.1.</span> <span class="toc-text">复习</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9E%E6%83%B3%EF%BC%9A%E7%83%B9%E9%A5%AA%E8%BF%87%E7%A8%8B"><span class="toc-number">4.0.1.1.</span> <span class="toc-text">回想：烹饪过程</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%B0%E4%BB%A3%E5%A4%84%E7%90%86%E5%99%A8"><span class="toc-number">4.1.</span> <span class="toc-text">现代处理器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BE%8B%E5%AD%90%EF%BC%9AKayvons-%E8%99%9A%E6%9E%84%E7%9A%84%E5%A4%9A%E6%A0%B8%E8%8A%AF%E7%89%87"><span class="toc-number">4.1.0.1.</span> <span class="toc-text">例子：Kayvons 虚构的多核芯片</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BE%8B%E5%AD%90%EF%BC%9AIntel-Skylake-Kaby-Lake-core"><span class="toc-number">4.1.0.2.</span> <span class="toc-text">例子：Intel Skylake&#x2F;Kaby Lake core</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BE%8B%E5%AD%90%EF%BC%9ANVIDIA-V100-GPU"><span class="toc-number">4.1.0.3.</span> <span class="toc-text">例子：NVIDIA V100 GPU</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E5%88%A9%E7%94%A8%E7%8E%B0%E4%BB%A3%E5%A4%84%E7%90%86%E5%99%A8%EF%BC%9F"><span class="toc-number">4.2.</span> <span class="toc-text">如何高效利用现代处理器？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8F%A6%E4%B8%80%E4%B8%AA%E4%BD%9C%E7%94%A8%EF%BC%9A%E5%A1%9E%E6%BB%A1%E8%AE%A1%E7%AE%97%E5%8D%95%E5%85%83"><span class="toc-number">4.2.1.</span> <span class="toc-text">多线程的另一个作用：塞满计算单元</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GPU-SIMT-Single-Instruction-Multiple-Thread"><span class="toc-number">4.2.2.</span> <span class="toc-text">GPU SIMT(Single Instruction Multiple Thread)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9E%E6%83%B3%EF%BC%9A%E6%80%9D%E8%80%83%E9%A2%98"><span class="toc-number">4.2.3.</span> <span class="toc-text">回想：思考题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98%EF%BC%9AC-i-A-i-B-i"><span class="toc-number">4.2.4.</span> <span class="toc-text">思考题：C[i] &#x3D; A[i] * B[i]</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%A6%E5%AE%BD-Bandwidth"><span class="toc-number">4.3.</span> <span class="toc-text">带宽 Bandwidth</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#101-%E5%85%AC%E8%B7%AF"><span class="toc-number">4.3.0.1.</span> <span class="toc-text">101 公路</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E5%B8%A6%E5%AE%BD"><span class="toc-number">4.3.1.</span> <span class="toc-text">内存带宽</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BE%8B%E5%AD%90%EF%BC%9A%E6%B4%97%E8%A1%A3%E6%9C%8D"><span class="toc-number">4.3.1.1.</span> <span class="toc-text">例子：洗衣服</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9E%E6%83%B3%EF%BC%9A%E6%A1%88%E4%BE%8B%EF%BC%9AC-i-A-i-B-i"><span class="toc-number">4.3.1.2.</span> <span class="toc-text">回想：案例：C[i] &#x3D; A[i] * B[i]</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ISCP"><span class="toc-number">4.4.</span> <span class="toc-text">ISCP</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ISPC-%E9%87%8D%E5%86%99-sinx"><span class="toc-number">4.4.1.</span> <span class="toc-text">ISPC 重写 sinx()</span></a></li></ol></li></ol></li></ol></div></div><footer><nobr>Published with <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a></nobr><wbr><nobr> Theme <a target="_blank" rel="noopener" href="https://github.com/Yue-plus/hexo-theme-arknights">Arknights</a></nobr><wbr><nobr> by <a target="_blank" rel="noopener" href="https://github.com/Yue-plus">Yue_plus</a></nobr></footer></aside></main><canvas id="canvas-dust"></canvas></body></html>